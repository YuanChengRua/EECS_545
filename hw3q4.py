# -*- coding: utf-8 -*-
"""HW3Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_wO2IXcvcfzpgVFMmksuw-VnpgI6q45C
"""

import numpy as np
import matplotlib.pyplot as plt
np.random.seed(0)

xtrain = np.load("housing_train_features.npy")
xtest = np.load("housing_test_features.npy")
ytrain = np.load("housing_train_labels.npy")
ytest = np.load("housing_test_labels.npy")

feature_names = np.load("housing_feature_names.npy", allow_pickle=True)
print("First feature name: ", feature_names[0])
print("Lot frontage for first train sample:", xtrain[0,0])

def normalization(input_mat):
  row_means = []
  row_vars = []
  for i in range(xtrain.shape[0]):
    sample_mean = np.mean(xtrain[i,:])
    sample_var = np.sum((xtrain[i, :] - sample_mean)**2) / xtrain.shape[1]
    row_means.append(sample_mean)
    row_vars.append(np.sqrt(sample_var))

    input_mat[i, :] = (input_mat[i, :] - sample_mean) / np.sqrt(sample_var) 

  return input_mat, row_means, row_vars

xtrain, row_means, row_vars = normalization(xtrain)
row_means = np.array(row_means)
row_means = row_means.reshape(-1, 1)

w0 = np.sum(ytrain) / n

def generate_what(xtrain, ytrain, lam, w, w0):
  d, n = xtrain.shape
  store_vals = np.ndarray((d, 0))
  for i in range(xtrain.shape[0]):
    innerpart = ytrain - w0 - np.dot(w.T, xtrain)
    ci = 2 * np.dot(innerpart, xtrain[i,:])
    ai = 2 * np.dot(xtrain[i,:].T, xtrain[i,:])
    w[i,0] = (ci / (ai + 2 * lam)) + (ai / (ai + 2 * lam)) * w[i,0]
    store_vals = np.concatenate((store_vals, w), axis = 1)
  return store_vals, w 

# Find the what for each iteration

w = np.ones((d, 1))
results = np.ndarray((d, 0))

for i in range(50):
  store_vals, w = generate_what(xtrain, ytrain, 100, w, w0)
  results = np.concatenate((results, store_vals), axis = 1)



converged_w = results[:,-1]
y_hat = w0 + np.dot(xtrain.T, converged_w)

total_vals = 0
for idx in range(ytrain.shape[0]):
  total_vals = total_vals + (ytrain[idx] - y_hat[idx]) ** 2

mse = total_vals / ytrain.shape[0]
# The MSE of training data set is 604.7157324765542


# The trajectories over iteration are shown below
for i in range(results.shape[0]):
  plt.plot(results[i,:])
plt.show()

# The learning curve is shown below 
all_vals = []
for i in range(results.shape[1]):
  total_vals = 0
  what = results[:,i]
  what = what.reshape(-1, 1)
  y_hat = w0 + np.dot(xtrain.T, what)
  for idx in range(ytrain.shape[0]):
    total_vals = total_vals + (ytrain[idx] - y_hat[idx]) ** 2
  
  total_vals = total_vals / ytrain.shape[0]
  all_vals.append(total_vals)

iter = np.linspace(0, 2899, 2900)

plt.plot(iter, all_vals)
plt.xlabel("# of iteration")
plt.ylabel("MSE of Training data")