# -*- coding: utf-8 -*-
"""HW2Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g1ahfj_5jSOBtYnj07S24D2b7kdCW-Cd
"""

import numpy as np
import matplotlib.pyplot as plt
import math


# Load the data set

x = np.load("E:\\FALL_dataset\\hw2p4_data\\fashion_mnist_images.npy")
y = np.load("E:\\FALL_dataset\\hw2p4_data\\fashion_mnist_labels.npy")

d, n = x.shape

i = 0 #Index of the image to be visualized
plt.imshow(np.reshape(x[:,i], (int(np.sqrt(d)),int(np.sqrt(d)))), cmap="Greys")
plt.show()

# Train test split for x and y
train_x = x[:, 0:5000]
test_x = x[:, 5000:]

train_y = y[:, 0:5000]
test_y = y[:, 5000:]
intersection = np.ones((1, 5000))
intersection_test = np.ones((1, 1000))

complete_train_x = np.vstack([intersection, train_x])
complete_test_x = np.vstack([intersection_test, test_x])

theta_ini = np.zeros((785, 1))  # Initialize the theta parameters and its transpose
theta_ini_transpose = theta_ini.T
flag = True
counter = 0
while flag:
  calculate_part = 0  # find the gradient of J(theta)
  for i in range(complete_train_x.shape[1]):
    var = np.reshape(train_y[:, i] * complete_train_x[:, i], (785, 1))
    numerator = np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i]))
    denominator = 1 + (np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i])))
    calculate_part = calculate_part - var * numerator / denominator
  calculate_part = calculate_part.reshape(785, 1)
  gradient = calculate_part + 2 * theta_ini

  calculate_part_hessian = 0  # find the hessian of J(theta)
  for i in range(train_x.shape[1]):
    var = np.outer(complete_train_x[:, i], complete_train_x[:, i])
    numerator = (np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i])))
    denominator = np.power((1 + (np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i])))), 2)
    calculate_part_hessian = calculate_part_hessian + var * numerator / denominator
  hessian = calculate_part_hessian + 2 * np.identity(785)
  inv_hessian = np.linalg.inv(hessian)

  prev_l = 0   # Calculate the value of J(theta) with old theta values
  for i in range(train_x.shape[1]):
      prev_l = prev_l + np.log(1 + np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i])))
  prev_j = prev_l + np.dot(theta_ini.T, theta_ini)

  theta_ini = theta_ini - np.dot(inv_hessian, gradient)  # update the theta values

  next_l = 0  # Calculate the value of J(theta) with new theta values
  for i in range(train_x.shape[1]):
      next_l = next_l + np.log(1 + np.exp((-1) * train_y[:, i] * np.dot(theta_ini.T, complete_train_x[:, i])))
  next_j = next_l + np.dot(theta_ini.T, theta_ini)

  counter = counter+1  # update the number of iterations
  print(counter)
  if abs(next_j - prev_j) / prev_j < 0.000001:    # if next_j and prev_j are close enough, stop the loop
      flag = False

# The number of iteration and the value of the objective function after convergence is shown below 
last_val = np.log(1 + np.exp(-train_y[:,i] * np.dot(theta_ini_transpose, complete_train_x[:,i]))) + np.dot(theta_ini_transpose, theta_ini)
print("The number of iteration is {}".format(counter))
# the value of J(theta) with the last group of thetas
print("Value of the objective function after convergence is {}".format(last_val))

p_list = []  # use the final thetas to generate the probability of each data point of the test set
for i in range(test_x.shape[1]):
  temp = np.exp(np.dot(theta_ini.T, complete_test_x[:,i])) / (1 + np.exp(np.dot(theta_ini.T,complete_test_x[:,i])))
  p_list.append(temp[0])

# if probability less than 0.5, assign label -1 otherwise, assign 1
label_list = []
for i,ele in enumerate(p_list):
  if ele <= 0.5:
    label_list.append(-1)
  else:
    label_list.append(1)

error_counter = 0
error_index = []  # find the index of the misclassification cases
for i in range(len(label_list)):
  if label_list[i] != test_y[:,i][0]:
    error_counter = error_counter + 1
    error_index.append(i)

# The test error is shown below
error_rate = error_counter / len(p_list)
print("The error rate is {}".format(error_rate))

# combine the index and its corresponding probability
error_p = [(i,p_list[i]) for i in error_index]
residual = []
for ele in error_p:
  residual.append((ele[0], abs(ele[1] - 0.5)))  # check the distance between its probability and 0.5
residual.sort(key = lambda x: x[1], reverse = True)  # Sort the residual by distance


fig = plt.figure(figsize=(28, 28))
columns = 5
rows = 4

for i in range(1, columns * rows +1):
  error_i = residual[i - 1][0]
  temp = np.reshape(test_x[:,error_i], (int(np.sqrt(784)),int(np.sqrt(784))))
  img = temp
  fig.add_subplot(rows, columns, i)
  plt.imshow(img,cmap="Greys")
  plt.title(str(test_y[:,error_i][0]))
plt.show()